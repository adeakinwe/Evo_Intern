





# Filtering Warnings
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

pd.set_option('display.max_columns', 300) #Setting column display limit
plt.style.use('ggplot') #Applying style to graphs





miceData = pd.read_csv("Data_Cortex_Nuclear.csv")


miceData.head()





miceData.shape


miceData.dtypes


miceData.info(verbose=True)





null_miceData = (miceData.isnull().sum()/len(miceData)*100).sort_values(ascending=False).head(10)
null_miceData





BCL2_N_null = miceData[miceData['BCL2_N'].isnull()]

BCL2_N_null[['MouseID','class','BCL2_N']].head(20)


miceData_num = miceData.select_dtypes(include= ['int64','float64']).columns

miceData[miceData_num].head()





for col in miceData_num:
    miceData[col].fillna(miceData[col].median(),inplace=True)


miceData.isnull().sum()





miceDataEncoded = pd.get_dummies(miceData,columns=['Genotype','Treatment','Behavior'],dtype= 'int')


miceDataEncoded.head()


miceDataEncoded.isnull().sum()/len(miceData)


miceDataEncoded['MouseID'] = miceDataEncoded['MouseID'].astype('category')


miceDataEncoded





from sklearn.preprocessing import MinMaxScaler

numeric_columns = miceDataEncoded.select_dtypes(include=['float64', 'int64']).columns

scaler = MinMaxScaler()

# Fit the scaler to the numeric columns and transform the data
miceData_scaled = miceDataEncoded.copy()
miceData_scaled[numeric_columns] = scaler.fit_transform(miceDataEncoded[numeric_columns])


miceData_scaled.head()





miceData_scaled.describe()


miceData_scaled.columns


miceData_scaled["Genotype_Control"].value_counts()


import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="whitegrid")
class_counts = miceData_scaled['class'].value_counts()
print(class_counts)
plt.figure(figsize=(10, 6))

# Create the bar chart
bar_chart = sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')

# Add titles and labels
plt.title('Class Distribution', fontsize=16)
plt.xlabel('Class', fontsize=14)
plt.ylabel('Count', fontsize=14)

# Add the count labels on top of each bar
for index, value in enumerate(class_counts.values):
    bar_chart.text(index, value + 0.5, str(value), ha='center', va='bottom', fontsize=12)

# Adjust the layout for better spacing
plt.tight_layout()

# Show the plot
plt.show()


import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
sns.set(style="whitegrid")
columns_to_exclude = ['Genotype_Control', 'Genotype_Ts65Dn', 'Treatment_Memantine', 'Treatment_Saline',
                      'Behavior_C/S', 'Behavior_S/C']
columns_to_plot = [col for col in miceData_scaled.columns if col not in columns_to_exclude]

# Plot histograms
miceData_scaled[columns_to_plot].hist(figsize=(20, 20), bins=20, color="pink")
plt.suptitle('Histograms of Data Variables', fontsize=16)
plt.xlabel('Value', fontsize=14)
plt.ylabel('Frequency', fontsize=14)
plt.tight_layout()
plt.show()


miceData_scaled.dtypes


import seaborn as sns
import matplotlib.pyplot as plt

# Select columns of interest for heatmap
columns_of_interest = ['NUMB_N',
                       'P70S6_N', 'pGSK3B_N', 'pPKCG_N', 'CDK5_N', 'S6_N', 'ADARB1_N',
                       'AcetylH3K9_N', 'RRP1_N', 'BAX_N', 'ARC_N', 'ERBB4_N', 'nNOS_N',
                       'Tau_N', 'GFAP_N', 'GluR3_N', 'GluR4_N', 'IL1B_N', 'P3525_N',
                       'pCASP9_N', 'PSD95_N', 'SNCA_N', 'Ubiquitin_N', 'pGSK3B_Tyr216_N',
                       'SHH_N', 'pS6_N', 'SYP_N', 'CaNA_N']

# Compute correlation matrix
correlation_matrix = miceData_scaled[columns_of_interest].corr()

# Plot heatmap
plt.figure(figsize=(18, 15))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f',
            annot_kws={'size': 10}, square=True)
plt.title('Correlation Heatmap of Protein Expression Levels')
plt.show()


#CHECKING CORRELATED FEATURES FOR POSSIBLE DROPPING

mask = np.triu(np.ones_like(miceData_scaled.corr(numeric_only=True), dtype=bool))
corr_tri_df = miceData_scaled.corr(numeric_only=True).mask(mask)

corr_tri_df


corr_col_to_drop = [i for i in corr_tri_df.columns if any(corr_tri_df[i]>0.90)]
print(corr_col_to_drop)


miceData_scaled.drop(labels=corr_col_to_drop,axis=1,inplace=True)


miceData_scaled.shape


# Explore relationships between proteins and classes
plt.figure(figsize=(12, 6))
sns.violinplot(x='class', y=columns_of_interest[0], data=miceDataEncoded)
plt.title('Violin Plot of Protein Expression Levels by Class')
plt.xlabel('Class')
plt.ylabel('Expression Level')
plt.show()





# Box plots to visualize protein expression levels by class
for protein in columns_of_interest:
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=miceDataEncoded, x="class", y=protein)
    plt.title(f"Box Plot of {protein} Expression Levels by Class")
    plt.show()


# Create a box plot for the first two proteins
proteins_of_interest = columns_of_interest[:2]

for protein in proteins_of_interest:
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=miceDataEncoded, x="class", y=protein)
    plt.title(f"Box Plot of {protein} Expression Levels by Class")
    plt.show()


# # Create a pairplot to visualize relationships between proteins and class
# sns.pairplot(miceDataEncoded[['NUMB_N', 'P70S6_N', 'class']],
#              hue="class",
#              diag_kind="kde",
#              markers=["o", "s", "D", "v", "^", "<", ">", "p"],
#              palette="husl")

# plt.show()








miceData_scaled.drop('MouseID',axis = 1,inplace=True )


from sklearn.feature_selection import SelectKBest, chi2

X = miceData_scaled.drop(['class','Genotype_Control', 'Genotype_Ts65Dn',
       'Treatment_Memantine', 'Treatment_Saline', 'Behavior_C/S',
       'Behavior_S/C'],axis=1)
y = miceData_scaled['class']  # Target variable

# Select top 10 features using chi-squared test
selector = SelectKBest(chi2, k=10)
X_selected = selector.fit_transform(X, y)


print('Original features: ', X.shape[1])
print('KBest features:', X_selected.shape[1])


from sklearn.feature_selection import VarianceThreshold
variances = X.var()
threshold = 0.01
selector = VarianceThreshold(threshold=threshold)
X_selected = selector.fit_transform(X)
selected_features = X.columns[selector.get_support()]



len(selected_features)


ax = pd.Series(variances, index=X.columns).plot(kind='bar', logy=True, color='lightgreen', edgecolor='black',figsize=(19, 6))
ax.axhline(threshold, ls='dotted', c='red')
plt.xticks(rotation=90)
plt.xlabel('Features')
plt.ylabel('Variance')
plt.title('Feature Variances with Variance Thresholding')
plt.show()


from sklearn.ensemble import RandomForestClassifier
import pandas as pd

# Create the random forest with your hyperparameters.
model = RandomForestClassifier(n_estimators=340)

# Fit the model to start training.
model.fit(X, y)

# Get the importance of the resulting features.
importances = model.feature_importances_

# Create a data frame for visualization.
final_miceDataEncoded = pd.DataFrame({"Features": pd.DataFrame(X).columns, "Importances": importances})
final_miceDataEncoded.set_index("Importances")

# Sort in ascending order to better visualization.
final_miceDataEncoded = final_miceDataEncoded.sort_values("Importances")

# Plot the feature importances in bars.
final_miceDataEncoded.plot.bar(color='teal',figsize=(19, 6))
plt.xticks(rotation=90)
plt.title("Feature Importances")
plt.show()



X.shape


final_miceDataEncoded.shape


final_miceDataEncoded['Importances'].sort_values(ascending=False)


selected_features = list(final_miceDataEncoded[final_miceDataEncoded['Importances']>0.005]['Features'])


len(selected_features)





from sklearn.model_selection import train_test_split


X = miceData_scaled.drop('class', axis=1)  # All columns except 'class'
y = miceData_scaled['class']  # The 'class' column

X = X[selected_features]


X





from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV


models = []
models.append(('LR', LogisticRegression()))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('GNB', GaussianNB()))
models.append(('SVM', SVC()))
models.append(('RF', RandomForestClassifier()))

#evaluate model
results = []
names = []
scoring = 'accuracy'
for name, model in models:
    kfold = KFold(n_splits=10, shuffle=True, random_state=7)
    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)
    results.append(cv_results)
    names.append(name)
    msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
    print(msg)


# boxplot algorithm comparison
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()


# Split Dataset
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)





def plot_classification_metrics(test_y, predicted_y):
    # Confusion matrix
    C = confusion_matrix(test_y, predicted_y)

    # Precision matrix
    A = (C/C.sum(axis=0))
    
    # Recall matrix
    B = (((C.T)/(C.sum(axis=1))).T)
    
    plt.figure(figsize=(20,4))
    
    labels = sorted(list(y_test.unique()))
   
    cmap=sns.light_palette("purple")
    plt.subplot(1,3,1)
    sns.heatmap(C, annot=True, cmap=cmap,fmt="d", xticklabels = labels, yticklabels=labels)
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title('Confusion matrix')
    
    plt.subplot(1,3,2)
    sns.heatmap(A, annot=True, cmap=cmap, xticklabels = labels, yticklabels=labels)
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title('Precision matrix')
    
    plt.subplot(1,3,3)
    sns.heatmap(B, annot=True, cmap=cmap, xticklabels = labels, yticklabels=labels)
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title('Recall matrix')
    
    plt.show()





# Initialize the SVM model
model = SVC(kernel='linear', random_state=42)

# Train the model
model.fit(X_train, y_train)


from sklearn.metrics import accuracy_score, classification_report

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Get a detailed classification report
print(classification_report(y_test, y_pred))



plot_classification_metrics(y_test, y_pred)


#HYPER PARAMETER TUNING

svc = SVC()

param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['linear', 'rbf']
}

grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)

grid_search.fit(X_train, y_train)

print(f"Best parameters: {grid_search.best_params_}")
print(f"Best cross-validation score: {grid_search.best_score_}")


best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Test accuracy: {accuracy}")

print(classification_report(y_test, y_pred))



plot_classification_metrics(y_test, y_pred)


train_accuracy = best_model.score(X_train, y_train)
test_accuracy = best_model.score(X_test, y_test)
print(f"Training Accuracy: {train_accuracy}")
print(f"Test Accuracy: {test_accuracy}")


cross_val_scores = cross_val_score(best_model, X_train, y_train, cv=5)
print(f"Cross-Validation Scores: {cross_val_scores}")
print(f"Mean Cross-Validation Score: {cross_val_scores.mean()}")





from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report


model = LogisticRegression(multi_class='multinomial')

model.fit(X_train, y_train)

# evaluating the model
y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))


plot_classification_metrics(y_test, y_pred)


# hyperparameter tuning
from sklearn.model_selection import GridSearchCV


param_grid = {
    'penalty': ['l1', 'l2', 'elasticnet', 'none'],
    'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],
    'max_iter': [300, 500, 1000, 1500]
}

grid_search = GridSearchCV(model, param_grid, cv=5)
grid_search.fit(X, y)


print(f"Best parameters: {grid_search.best_params_}")
print(f"Best cross-validation score: {grid_search.best_score_}")


best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)


accuracy = accuracy_score(y_test, y_pred)
print(f"Validation accuracy: {accuracy}")





from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import joblib


# Initialize and training
rf = RandomForestClassifier(random_state=42)


# Define the parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [3, 5, 7],
    'min_samples_split': [10, 20, 30],
    'min_samples_leaf': [4, 6, 8],
    'max_features': ['sqrt']
}

# GridSearch for Hyperparameter tuning
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)


# Best model
best_rf = grid_search.best_estimator_

# Print the best parameters
print(f"Best Parameters: {grid_search.best_params_}")


# Cross-validation for model evaluation
cv_scores = cross_val_score(best_rf, X_train, y_train, cv=5)
print(f"Cross-Validation Scores: {cv_scores}")
print(f"Mean CV Score: {cv_scores.mean()}")


# predict on test
Y_pred = best_rf.predict(X_test)


# Evaluation
accuracy = accuracy_score(y_test, Y_pred)
precision = precision_score(y_test, Y_pred, average='weighted')
recall = recall_score(y_test, Y_pred, average='weighted')
f1 = f1_score(y_test, Y_pred, average='weighted')
conf_matrix = confusion_matrix(y_test, Y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")
print(f"Confusion Matrix:\n{conf_matrix}")


plot_classification_metrics(y_test, Y_pred)
